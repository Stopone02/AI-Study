{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5933a622-d2b2-4f70-aded-2bc93fffd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112fcf62-c909-4f89-bdb4-fcc8bb499570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is cpu\n"
     ]
    }
   ],
   "source": [
    "# 분석 환경 설정\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")\n",
    "\n",
    "print('Current device is', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44137485-8665-4273-a0ff-1459abf5f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameter 지정\n",
    "batch_size = 50\n",
    "epoch_num = 15\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf8ed66-a71d-4ad8-b1f7-16b4f086f802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data:  60000\n",
      "number of test data:  10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 불러오기\n",
    "train_data = datasets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root = './data', train = False, transform = transforms.ToTensor())\n",
    "\n",
    "print('number of training data: ', len(train_data))\n",
    "print('number of test data: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa12195-5edb-4bd7-9c66-715bbbbde0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST 데이터 확인하기\n",
    "image, label = train_data[0]\n",
    "\n",
    "plt.imshow(image.squeeze().numpy(), cmap = 'gray')\n",
    "plt.title('label : %s' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04366c93-1cc5-467f-b50d-4be21f9da8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            | type                      | size\n",
      "Num of Batch    |                           | 1200\n",
      "first_batch     | <class 'list'>            | 2\n",
      "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
      "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# 미니 배치 구성하기\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()\n",
    "print('{:15s} | {:<25s} | {}'.format('name', 'type', 'size'))\n",
    "print('{:15s} | {:<25s} | {}'.format('Num of Batch', '', len(train_loader)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1762c377-b5fd-4a4e-a810-6b1d6a4798cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 구조 설계하기\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108a238c-a65c-44d0-a8c9-e8ecc11d0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 및 손실 함수 정의\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa135ad-ec10-4a1b-a904-e05559c4f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 설계한 CNN 모형 확인하기\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc98cabf-9d08-485b-b5c0-1b96bec56d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 0\tLoss: 2.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1000\tLoss: 0.291\n",
      "Train Step: 2000\tLoss: 0.214\n",
      "Train Step: 3000\tLoss: 0.064\n",
      "Train Step: 4000\tLoss: 0.030\n",
      "Train Step: 5000\tLoss: 0.166\n",
      "Train Step: 6000\tLoss: 0.115\n",
      "Train Step: 7000\tLoss: 0.016\n",
      "Train Step: 8000\tLoss: 0.142\n",
      "Train Step: 9000\tLoss: 0.165\n",
      "Train Step: 10000\tLoss: 0.021\n",
      "Train Step: 11000\tLoss: 0.009\n",
      "Train Step: 12000\tLoss: 0.016\n",
      "Train Step: 13000\tLoss: 0.016\n",
      "Train Step: 14000\tLoss: 0.049\n",
      "Train Step: 15000\tLoss: 0.005\n",
      "Train Step: 16000\tLoss: 0.067\n",
      "Train Step: 17000\tLoss: 0.015\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.train()\n",
    "i = 0\n",
    "for epoch in range(epoch_num):\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print('Train Step: {}\\tLoss: {:.3f}'.format(i, loss.item()))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41188cbc-92bc-4508-9261-bdbe172d400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy: 99.06%\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1]\n",
    "    correct += prediction.eq(target.data).sum()\n",
    "\n",
    "print('Test set: Accuracy: {:.2f}%'.format(100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8412ed2-d2fc-4f91-8074-f644dbce6494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
